vocab_file: 'config/vocab.txt'
vocab_size: 104
batch_size: 64
block_size: 256
max_iters : 3000
eval_interval : 100
learning_rate : 0.001
eval_iters : 200
n_embed : 384
n_head : 6
n_layer : 6
expert_dropout : 0.1
attention_dropout : 0.1
n_experts : 4
model_dir : 'model_out'
model_name : 'my_llm.pth'